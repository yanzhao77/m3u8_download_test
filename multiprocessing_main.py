import os
import json
import subprocess
from multiprocessing import Pool, cpu_count
from playwright.sync_api import sync_playwright


# ============================================
# 1. è·å–å‰§é›†æ’­æ”¾é¡µï¼ˆä» playlist ul â†’ liï¼‰
# ============================================
def find_page(url):
    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True)
        page = browser.new_page()
        page.goto(url)

        page.wait_for_selector("#playlist")

        li_list = page.query_selector_all('//*[@id="playlist"]/li')

        href_map = {}
        for li in li_list:
            a = li.query_selector("a")
            if a:
                name = a.inner_text().strip()
                href = a.get_attribute("href")
                href_map[name] = href

        browser.close()
        return href_map


# ============================================
# 2. è·å– m3u8
# ============================================
def get_m3u8(url):
    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True)
        page = browser.new_page()

        m3u8_list = []

        def on_request(request):
            req_url = request.url
            if ".m3u8" in req_url:
                print("ğŸ¯ æ•è·åˆ° M3U8:", req_url)
                m3u8_list.append(req_url)

        page.on("request", on_request)
        print(f"â³ åŠ è½½é¡µé¢ï¼š{url}")

        page.goto(url)
        page.wait_for_timeout(5000)

        browser.close()
        return list(set(m3u8_list))


# ============================================
# 3. å¤šè¿›ç¨‹ + yt-dlp ä¸‹è½½
# ============================================
def download_one(args):
    ep_name, m3u8_url, save_dir = args
    output_path = os.path.join(save_dir, ep_name + ".mp4")

    cmd = [
        "yt-dlp",
        "-N", "16",          # 16çº¿ç¨‹ä¸‹è½½
        "-o", output_path,
        m3u8_url
    ]

    print(f"\nâ¬‡ï¸ ä¸‹è½½å¼€å§‹ï¼š{ep_name}")
    subprocess.run(cmd)
    print(f"âœ… å®Œæˆï¼š{output_path}")

    return True


def parallel_download(m3u8_map, save_dir):
    tasks = []
    for ep_name, m3u8_url in m3u8_map.items():
        tasks.append((ep_name, m3u8_url, save_dir))

    workers = min(len(tasks), cpu_count())
    print(f"\nğŸ”¥ å¤šè¿›ç¨‹ä¸‹è½½å¯åŠ¨ï¼š{workers} workers\n")

    with Pool(workers) as pool:
        pool.map(download_one, tasks)


# ============================================
# 4. ä¸»å‡½æ•°ï¼šå…¨é›†è‡ªåŠ¨åŒ–
# ============================================
if __name__ == "__main__":
    root_page = "https://xiaoxintv.cc/index.php/vod/play/id/205584/sid/1/nid/1.html"
    base_url = "https://xiaoxintv.cc/"
    save_dir = r"E:\video\ç”Ÿæ´»å¤§çˆ†ç‚¸ ç¬¬äº”å­£"

    os.makedirs(save_dir, exist_ok=True)

    print("ğŸ” è·å–å‰§é›†åˆ—è¡¨...")
    ep_map = find_page(root_page)

    all_m3u8 = {}

    # éå†æ¯ä¸€é›†
    for ep_name, ep_path in ep_map.items():
        play_url = base_url + ep_path
        print(f"\n====== å¤„ç† {ep_name} ======")
        print(f"æ’­æ”¾é¡µï¼š{play_url}")

        m3u8_list = get_m3u8(play_url)
        if not m3u8_list:
            print("âŒ æ²¡æœ‰æ‰¾åˆ° m3u8")
            continue

        # åªå–ç¬¬ä¸€ä¸ª
        all_m3u8[ep_name] = m3u8_list[0]

        print(f"ğŸ¯ {ep_name} â†’ {m3u8_list[0]}")

    # ä¿å­˜ JSON
    json_path = os.path.join(save_dir, "m3u8_list.json")
    json.dump(all_m3u8, open(json_path, "w", encoding="utf-8"), ensure_ascii=False, indent=4)

    print("\nğŸ“„ å·²å†™å…¥ m3u8 åˆ—è¡¨ï¼š", json_path)

    # ========= å¼€å§‹å¤šè¿›ç¨‹ä¸‹è½½ =========
    parallel_download(all_m3u8, save_dir)

    print("\n================ å…¨éƒ¨å®Œæˆï¼ ================")
